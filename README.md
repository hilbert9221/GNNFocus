[TOC]
## About
Focused areas in graph neural networks (GNNs). Written in both English and Chinese.
## Template
#### A Possible Subfield
- **Title in bold font.** *Authors in italic font.* Journal / Conference year in normal font.
  - group (optional): a famous group, e.g., Someone's group, Some University.
  - [paper (must)](link), [code (optional)](link), [slides (optional)](link), [project page (optional)](link), [review (optional)](link) 
  - blogs (optional): [blogs](link)
  - contributions (must)
    - In flexible forms.
    - About the method.
    - About the experiments.
  - [note (optional)](link): write a note in markdown and provide the path of the file.
    - path: `nodes/field/title_conference&year.md`
## Expressive Power
#### Permutation Equivariant GNNs
## Pre-training / Self-supervised Learning
#### Self-supervised / Unsupervised Learning
#### Pre-training
- **Strategies for Pre-training Graph Neural Networks.** *Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, Jure Leskovec.* ICLR 2020.
  - group: Jure Leskovec's group, Stanford University
  - [paper](https://openreview.net/pdf?id=HJlWWJSFDH), [code](https://github.com/snap-stanford/pretrain-gnns), [project page](http://snap.stanford.edu/gnn-pretrain/), [review](https://openreview.net/forum?id=HJlWWJSFDH)
  - blogs: [CSDN](https://blog.csdn.net/fnoi2014xtx/article/details/107066797)
  - contributions
    - method
      - node level (unsupervised)
        - Context Prediction
        - Attribute Masking
      - graph level (supervised)
    - data
      - [Biology](http://snap.stanford.edu/gnn-pretrain/data/bio_dataset.zip)
      - [Chemistry](http://snap.stanford.edu/gnn-pretrain/data/chem_dataset.zip)
  - [note](notes/pre-train_self-supervised/Strategies%20for%20Pre-training%20Graph%20Neural%20Networks_ICLR2020.md)
## Deep GNNs
## Scalable GNNs
## Dynamic GNNs
## Hypergraph
## GNNs for Recommendation Systems
## GNNs for Neural Relational Inference
