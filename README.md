[TOC]
- [About](#about)
- [Template](#template)
    - [A Possible Subfield](#a-possible-subfield)
- [Expressive Power](#expressive-power)
- [Pre-training / Self-supervised Learning](#pre-training--self-supervised-learning)
- [Deep GNNs](#deep-gnns)
- [Scalable GNNs](#scalable-gnns)
- [Hierarchical GNNs](#hierarchical-gnns)
- [Dynamic GNNs](#dynamic-gnns)
- [Hypergraph Neural Networks](#hypergraph-neural-networks)
- [GNNs for Neural Relational Inference](#gnns-for-neural-relational-inference)
## About

Focused areas in graph neural networks (GNNs). Written in both English and Chinese. Contributions are welcomed!

## Template

#### A Possible Subfield

- **Title in bold font.** *Authors in italic font.* Journal / Conference year in normal font.
  - resources: [paper (must)](README.md), [code (optional)](README.md), [slides (optional)](README.md), [project page (optional)](README.md), [review (optional)](README.md), [blogs (optional)](README.md), [m](README.md)[y](README.md)[ note (optional)](README.md)
  - contributions (must)
- **Semi-Supervised Classification with Graph Convolutional Networks.** *Thomas N. Kipf, Max Welling.* ICLR 2017.
  - resources: [paper](https://openreview.net/pdf?id=SJU4ayYgl), [code](https://github.com/tkipf/gcn), [review](https://openreview.net/pdf?id=SJU4ayYgl), [blog](http://tkipf.github.io/graph-convolutional-networks/)
  - contributions:
    - A simple and numerically stable GCN in the spectral domain.
    - Pointing out the connection between GCN and 1st-order Weisfeiler-Lehma test.
    - Empirically showing that the performance may degenerate as GCN goes deep.

## [Expressive Power](subfields/Expressive%20Power.md)
- Intro: Expressive power of GNNs and permutation equivariant GNNs.
- Survey: **A Survey on The Expressive Power of Graph Neural Networks.** *Ryoma Sato.* CoRR 2020. [paper](https://arxiv.org/pdf/2003.04078v4)
- Notes: [cnblogs](https://www.cnblogs.com/hilbert9221/p/14443747.html)

## [Pre-training / Self-supervised Learning](subfields/Pre-training+Self-supervised%20Learning.md)
- Introï¼šPre-training GNNs or training GNNs in a self-supervised manner to allow better generalization.
- Notes: [cnblogs](https://www.cnblogs.com/hilbert9221/p/14375512.html)
## [Deep GNNs](subfields/Deep%20GNNs.md)
- Intro: Analyzing the over-smoothing problem of GNNs and explore possible solutions to make GNNs deep.

## [Scalable GNNs](subfields/Scalable%20GNNs.md)

## [Hierarchical GNNs](subfields/Hierarchical%20GNNs.md)

## [Dynamic GNNs](subfields/Dynamic%20GNNs.md)

## [Hypergraph Neural Networks](subfields/Hypergraph%20Neural%20Networks.md)

<!-- ## [GNNs for Recommendation Systems](subfields/GNNs%20for%20Recommendation%20Systems.md) -->

<!-- ## [GNNs for Traffic Flow Forecasting](subfields/GNNs%20for%20Traffic%20Flow%20Forecasting.md) -->

## [GNNs for Neural Relational Inference](subfields/GNNs%20for%20Neural%20Relational%20Inference.md)
- Intro: Jointly inferring the interacting relations and learning the dynamics of dynamical systems in an unsupervised manner.
- First paper: **Neural Relational Inference for Interacting Systems.** ICML 2018. [paper](http://proceedings.mlr.press/v80/kipf18a/kipf18a.pdf)

<!-- ## [Miscellaneous](subfields/Miscellaneous.md) -->

